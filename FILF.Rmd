---
title: "R code file for fixed-effects inference for longitudinal functional data"
author: 
- Ruonan Li^[Department of Statistics, North Carolina State University]
- Luo Xiao^[Department of Statistics, North Carolina State University]
- Ekaterina Smirnova^[Department of Biostatistics, Virginia Commonwealth University ]
- Erjia, Cui^[Department of Biostatistics, Johns Hopkins Bloomberg School of Public Health]
- Andrew, Leroux^[Department of Biostatistics and Informatics, Colorado School of Public Health]
- Ciprian M. Crainiceanu^[Department of Biostatistics, Johns Hopkins Bloomberg School of Public Health]
date: \today
header-includes:
output: pdf_document
---

**Introduction**

In this document, a complete implementation of the proposed fixed-effects estimate method considering complex functional mixed-effects is evaluated. Moreover, comparisons with the navie estimate by `pffr` function and the bootstrap method are evaluated using a dataset (100 subjects whose visit times follow Unif[3,6]) with unspeicified covariance structure. The document is organized as follows. 

Section 1 gives the main code (function `fgee`) corresponding to the proposed fixed-effects estimate method, and the code (function `fgee.bp`), corresponding to the bootstrap method in the paper. 

Section 2 gives the code to generate datasets (function `GenerateData`) which are used to evaluate fixed-effects estimate methods in section 1. We can use the `GenerateData` function to generate data with three different types of covariance structures. They are independent, exchangeable and unspecified. We apply the several methods on the same dataset in Section 2.2. In bootstrap method, the default number of resampling is 300. However, since the bootstrap method takes a long time to get results (about 16 minutes with resampling 300 times and about 2.5 minutes with resampling 50 times), we commented the part of implementing bootstrap by pound symbol. If you are interest in bootstrap results, please delete pound symbols in this part and run the code. 

Section 3 visualizes the outputs, including eigendecomposition, the mean function estimated by `pffr` function and the mean function estimated by `fgee` function. 

Section 4 shows hypothesis tests about covariance structures. Functions about testing are given and we show numerical results of testing the covariance structure of three types of data. Due to time limit, we only show the results of testing data with unspecifided covariance structure and put pound symbols on other types of data. The testing methods depend on bootstrap to get p-values and the default number of resmapling is 1000 (takeing about 1 minutes). It takes about 3 minutes to compile this Rmd file. 


**1. Main code **
```{r message=FALSE, echo=FALSE}
installed.packages(c("refund", "face","MASS", "mgcv","ggplot2","gridExtra",
                     "fields","lme4","matrixcalc","Matrix", "Bolstad", "splines"))

############################################################
# fgee
############################################################
library(face)
library(mgcv)

fgee <- function(formula, Y, Cov, s, subjID, Tij, numLongiPoints = 41, 
                 control = list(FPCA1.pve=0.95, FPCA2.pve=0.95,  
                                FPCA1.knots=20, FPCA2.knots=12), 
                 corstr = c("unspecified", "exchangeable","independent")){

  # Arguments:
  # 1.fomular 
  # parameter fomular: a formula expression which indicates a linear relationship
  # between Y and Cov
  #
  # 2.data 
  # parameter Y -- a matrix of which each row corresponds to one curve observed 
  # on a regular and dense grid(dimension of N by m; N=total number of observe
  # functions; m=number of grid points) 
  # parameter Cov -- including all covariates of interest.      
  # parameter s -- argvals a string indicating the functional domain variable 
  # name in data   
  # parameter subjID -- subject id; vector of length N with each element 
  # corresponding a row of Y
  # parameter Tij -- actual time of visits at which a function is observed
  # parameter numLongiPoints -- total number of evaluation time points for visits;
  # defaults to 41
  # 
  # 3.parameter control: a list with the named components: 
  # FPCA1.pve representing proportion of variance explained used to choose the 
  # number of principal components, defaults to 0.95; 
  # FPCA2.pve only needed for corstr of type "unspecified", defaults to 0.95; 
  # FPCA1.knots representing number of knots to use or the vectors of knots 
  # used for obtain a smooth estimate of a covarance function; defaults to 20; 
  # FPCA2.knots only needed for corstr of type "unspecified", defaults to 12
  #
  # 4.model:
  # parameter corstr -- type of covariance structure considering in model

  ############################################################   
  
  if (is.null(control$FPCA1.pve))
    stop("Invalid control list. The value of parameter FPCA1.pve in control is required")
  if (is.null(control$FPCA2.pve) & corstr == "unspecified")
    stop("Invalid control list. The value of parameter FPCA2.pve in control is required")
  if (is.null(control$FPCA1.knots))
    stop("Invalid control list. The value of parameter FPCA1.knots in control is required")
  if (is.null(control$FPCA2.knots) & corstr == "unspecified")
    stop("Invalid control list. The value of parameter FPCA2.knots in control is required")
  
  
  model.formula <- as.character(formula)
  stopifnot(model.formula[1] == "~" & length(model.formula) == 3)
  #compile the formula again
  formula <- paste("Y", model.formula[1], model.formula[3])
  #select covariates are used in formula
  Cov.fm <- c() 
  for(i in 1:ncol(Cov)){
    if(grepl(colnames(Cov)[i], model.formula[3])){
      Cov.fm <- c(Cov.fm, i)
    }
  }
  
  TT <- seq(min(Tij), max(Tij), length.out=numLongiPoints) #Tij close to TT[v]
  visitID <- sapply(Tij, function(a) which(abs(TT-a) == min(abs(TT-a))))
  psi.MF <- NULL # psi at Tij
  # holder for estimation results
  psi <- NULL
  # a simple vector to matrix conversion function
  vec2mat <- function(x){matrix(x,ncol=length(s),byrow=TRUE)}
  
  # additional setups
  k0 <- 10 #number of basis functions for fixed effects functions
  bs <- "ps"
  # vectorize data
  y <- c(t(Y))
  t <- rep(s,times=nrow(Y))
  for(i in 1:length(Cov.fm)){
    assign(colnames(Cov)[Cov.fm[i]], Cov[,Cov.fm[i]])
    assign(paste("x", i, sep=""), rep(Cov[,Cov.fm[i]], each=length(s))) 
  }
  ###########################################
  # Step 1: Initial mean estimate
  ##########################################

  # initial mean estimates
  fit_init <- pffr(as.formula(formula), yind=s, algorithm="bam",
                   bs.yindex = list(bs = bs, k = k0, m = c(2, 2))) #initial fit
  Y.mean_init <- predict(fit_init, type="terms")
  Y.mean.init <- fitted(fit_init) #fitted means
  Y.resid <- as.matrix(Y - Y.mean.init)

  # initial estimation of beta(s) and their stardard error
  plot.data <- {
    pdf(NULL)
    plot.init <- plot(fit_init,n=length(s), seWithMean=TRUE, pages=1)
    invisible(dev.off())
  }
  beta.init.0 <- plot.init[[1]]$fit + fit_init$coefficients[1]
  beta.init.cov <- matrix(unlist(lapply(1:length(Cov.fm), function(x)
     plot.init[[x+1]]$fit)),ncol=length(Cov.fm),byrow=FALSE)
  beta.init = cbind(beta.init.0, beta.init.cov)
  # To get stardard error of initial beta(s)
  beta.init.se <- matrix(unlist(lapply(1:(length(Cov.fm)+1), function(x)
     plot.init[[x]]$se/2)),ncol=(length(Cov.fm)+1),byrow=FALSE)
  ########################################
  # Step 2: Estimate marginal eigenfunctions
  ########################################
  fpca_margin <- fpca.face(Y.resid, center = FALSE, argvals=s, 
                           knots=control$FPCA1.knots, pve=control$FPCA1.pve)
  phi <- fpca_margin$efunctions*sqrt(length(s))
  lambda.phi <- fpca_margin$evalues/length(s)
  
  ########################################
  # Step 3: Re-estimate setup
  ########################################
  
  if(corstr == "unspecified"){
    #################################################
    # Estimate conditional eigenfunctions using faces
    #################################################
    scores <- fpca_margin$scores/sqrt(length(s))
    # convert scores into data frame
    data_scores <- list()
    for(k in 1:ncol(scores))
      data_scores[[k]] <- data.frame(y = scores[,k], argvals = Tij, subj = subjID)
    
    # convert data into faces structure
    T_dense <- seq(0,1, length.out=numLongiPoints)
    # fit faces
    fpca_condition <- lapply(data_scores,function(x){
      face.sparse(x, argvals.new = T_dense, center = FALSE,
                  newdata = x, calculate.scores = TRUE, pve = control$FPCA2.pve,
                  knots = control$FPCA2.knots)
    })
    
   # add sigma as eigenvalue to select new eigenvalues and eigenfunctions
    psi <- lapply(fpca_condition,function(x){as.matrix(x$eigenfunctions)})
    lambda.psi <- lapply(fpca_condition,function(x){x$eigenvalues})
    sigma2 <- lapply(fpca_condition,function(x){x$sigma2}) 
    # calculate the sum of selected lambdas and sigma2 which will be used to get 
    # the proportion of the lambda later get the sum of all lambda and sigma2
    lambda.sum <- sum(unlist(lambda.psi)) + sum(unlist(sigma2)) 
    # total pve explained by sigma2
    sigma2.pve <- sum(unlist(sigma2)/lambda.sum)
    # the proportion of pve explained by lambda
    lambda.pve <- sort(unlist(lambda.psi)/lambda.sum, decreasing=TRUE)
    # find the rank of the smallest lambda.psi we select
    rank <- which(cumsum(lambda.pve)+sigma2.pve > control$FPCA2.pve)[1]
    # the value of the smallest lambda.psi we select
    threshold <- sort(unlist(lambda.psi), decreasing=TRUE)[rank]
    
    # calculate psi's at each point of Tij
    psi.MF <- lapply(fpca_condition,function(x){
      as.matrix(as.matrix(x$eigenfunctions)[visitID,])})
    
    ########################################
    # Assign global eigenfunctions
    ########################################
    efuncs <- list()
    index <- 0
    for(k in 1:ncol(phi)){
      efuncs[[k]] <- psi.MF[[k]]%x%phi[,k]
      for(j in 1:ncol(psi.MF[[k]])){
    # if the eigenvalue is large enough, then we would select its eigenfunctions as basis
        if(lambda.psi[[k]][j] >= max(threshold, 0.05*lambda.sum)){ 
          index <- index + 1
          assign(paste("efunc",index,sep=""), efuncs[[k]][,j], envir = parent.frame())
        }
      }
    }
    
    # select all error terms(sigma2) to build up independent part. In this way, 
    # exchangeable and independent model are nested in unspcified model
    efuncs2 <- list()
    index2 <- 0  
    for(k in 1:ncol(phi)){
      efuncs2[[k]] <- rep(phi[,k], times = nrow(Y))
      index2 <- index2 + 1
      assign(paste("efunc2",index2,sep=""), efuncs2[[k]], envir = parent.frame()) 
    }
    
  }#end if corstr == unspecified
  
  if(corstr == "exchangeable"){
    
    ########################################
    # Assign global eigenfunctions
    ########################################
    efuncs <- list()
    index <- 0
    for(k in 1:ncol(phi)){
      efuncs[[k]] <- rep(phi[,k], times = nrow(Y))
      index <- index + 1
      assign(paste("efunc",index,sep=""), efuncs[[k]], envir = parent.frame()) 
    } 
  }#end if corstr == exchangeable

  if(corstr == "independent"){
    
    ########################################
    # Assign global eigenfunctions
    ########################################
    efuncs <- list()
    index <- 0
    for(k in 1:ncol(phi)){
      efuncs[[k]] <- rep(phi[,k], times = nrow(Y))
      index <- index + 1
      assign(paste("efunc", index, sep=""), efuncs[[k]], envir = parent.frame()) 
    } 
  }#end if corstr == independent
  
  ########################################
  # Step 4: Re-estimate model
  ########################################
  
  g <- rep(as.factor(subjID),each=length(s))
  g_vis <- rep(as.factor(paste(subjID,"_",visitID,sep="")),each=length(s)) 
  
  model0 <- paste("s(t, by=x",1:length(Cov.fm),", bs=bs,k=k0) ", collapse="+", sep="")
  model <- paste("y ~ s(t, bs=bs,k=k0) +", model0)
  phiForm <- paste("s(g, by = efunc",1:index,", bs='re') ", collapse="+",sep="")
  
  if(corstr == "unspecified"){
    if(index > 0){
      phiForm_vis<-paste("s(g_vis, by = efunc2",1:index2,", bs='re') ", collapse="+",sep="")
      newformula<-paste(model, "+", phiForm, "+", phiForm_vis)
    }else{
      phiForm_vis<-paste("s(g_vis, by = efunc2",1:index2,", bs='re') ", collapse="+",sep="")
      newformula <- paste(model, "+", phiForm_vis)
    }
  }#end if corstr == unspecified
  
  if(corstr == "exchangeable"){
    phiForm_vis <- paste("s(g_vis, by = efunc",1:index,", bs='re') ", collapse="+",sep="")
    newformula <- paste(model, "+", phiForm, "+", phiForm_vis)
  }#end if corstr == exchangeable
  
  if(corstr == "independent"){
    phiForm_vis <- paste("s(g_vis, by = efunc",1:index,", bs='re') ", collapse="+",sep="")
    newformula <- paste(model, "+", phiForm_vis)
  }#end if corstr == independent

  fit <- bam(as.formula(newformula), discrete = TRUE, nthreads = 2)

  ########################################
  # Step 5: Model fit
  ########################################
  
  Y.pred <- predict(fit, type="terms")
  Y.mean <- rowSums(Y.pred[,1:(length(Cov.fm)+1)]) + fit$coefficients[1]
  Y.mean <- vec2mat(c(Y.mean))
  sigma2 <- fit$sig2
  
  # estimation of beta(s) and their stardard error
  plot.data <- {
    pdf(NULL)
    plot <- plot(fit,n=length(s),seWithMean=TRUE, pages=1)
    invisible(dev.off())
  }
  beta.0 <- plot[[1]]$fit + fit$coefficients[1]
  beta.cov <- matrix(unlist(lapply(1:length(Cov.fm), function(x) plot[[x+1]]$fit)),
                     ncol=length(Cov.fm),byrow=FALSE)
  beta = cbind(beta.0, beta.cov)
  # To get stardard error of initial beta(s)
  beta.se <- matrix(unlist(lapply(1:(length(Cov.fm)+1), function(x) plot[[x]]$se/2)),
                    ncol=(length(Cov.fm)+1),byrow=FALSE)
  
  return(list(phi = phi, psi=psi,
              Y.mean = Y.mean, 
              Y.mean.init = Y.mean.init,
              beta = beta,
              beta.init = beta.init,
              beta.se = beta.se,
              beta.init.se = beta.init.se,
              sigma2 = sigma2,
              final.fit = fit,
              corstr = corstr))
}  

############################################################
# naive estimate with bootstrap to with confidence band
############################################################

fgee_initBp <- function(formula, Y, Cov, s, subjID, Tij,
                        numLongiPoints = 41, n.Bp=300){
  
  # Arguments:
  # The bootstrap algorithm is from Park et al. (2017)
  # 1.fomular 
  # parameter fomular: a formula expression which indicates a linear relationship
  # between Y and Cov
  #
  # 2.data 
  # parameter Y -- a matrix of which each row corresponds to one curve observed 
  # on a regular and dense grid (dimension of N by m; N=total number of observed
  # functions; m=number of grid points) 
  # parameter Cov -- including all covariates of interest.      
  # parameter s -- argvals a string indicating the functional domain variable 
  # name in data parameter subjID -- subject id; vector of length N with each 
  # element corresponding a row of Y
  # parameter Tij -- actual time of visits at which a function is observed
  # n.Bp: the times of resampling; default value is 300
  
  # formula for initial estimate
  model.formula <- as.character(formula)
  stopifnot(model.formula[1] == "~" & length(model.formula) == 3)
  # complie the formula again
  formula <- paste("Y", model.formula[1], model.formula[3])
  # select covariates are used in formula
  Cov.fm <- c() 
  for(i in 1:ncol(Cov)){
    if(grepl(colnames(Cov)[i], model.formula[3])){
      Cov.fm <- c(Cov.fm, i)
    }
  }
  n.cov <- length(Cov.fm)
  subjID.uniq <- unique(subjID)
  
  # additional setups
  k0 <- 10 #number of basis functions for fixed effects functions
  bs <- "ps"
  for(i in 1:n.cov){
    assign(colnames(Cov)[Cov.fm[i]], Cov[,Cov.fm[i]])
  }
  ###########################################
  # Step 1: Initial mean estimate
  ##########################################
  
  # initial mean estimates
  fit_init <- pffr(as.formula(formula), yind=s, algorithm = "bam",
                   bs.yindex = list(bs = bs, k = k0, m = c(2, 2))) #initial fit
  Y.mean_init <- predict(fit_init, type="terms")
  Y.mean.init <- fitted(fit_init) #fitted means
  
  # initial estimation of beta(s) 
  plot.data <- {
    pdf(NULL)
    plot.init <- plot(fit_init,n=length(s), seWithMean=TRUE, pages = 1)
    invisible(dev.off())
  }
  beta.init.0 <- plot.init[[1]]$fit + fit_init$coefficients[1]
  beta.init.cov <- matrix(unlist(lapply(1:n.cov, function(x) plot.init[[x+1]]$fit)),
                          ncol=n.cov,byrow=FALSE)
  beta.init = cbind(beta.init.0, beta.init.cov)

  #####################################################################
  # Step 2: To get confidence bands of initial beta(s) by bootstroap
  ####################################################################

  for(i in 1:n.Bp){
    # resample the subject indexa from the index set
    index <- sample(subjID.uniq, size=length(subjID.uniq), replace=TRUE) 
    # find correspending rows to original data for subjects from the resample set 
    Bp.row <- unlist(lapply(1:length(index), function(i){which(subjID==index[i])}))
    Y.Bp <- Y[Bp.row, ]
    Cov.Bp <- Cov[Bp.row, Cov.fm]
    colnames(Cov.Bp) <- paste("X.Bp", 1:n.cov, sep="")
    # formula for bootstrap estimate
    formula.Bp <- paste("Y.Bp", "~", paste("X.Bp", 1:n.cov, collapse="+", sep=""))
    # bootstrap estimates for beta(s)
    fit.Bp <- pffr(as.formula(formula.Bp), yind=s, data=data.frame(Y.Bp=Y.Bp, Cov.Bp),
                   algorithm = "bam", bs.yindex = list(bs=bs, k=k0, m=c(2, 2))) 
    plot.data <- {
      pdf(NULL)
      plot.Bp <- plot(fit.Bp,n=length(s),seWithMean=TRUE,pages = 1)
      invisible(dev.off())
    }
    
    if(i==1){
      beta.Bp <- lapply(1:(n.cov+1), function(x) plot.Bp[[x]]$fit)
      beta.Bp[[1]] <- beta.Bp[[1]] + fit.Bp$coefficients[1]
    } else {
      for(kk in 1:(n.cov+1)){
        beta.Bp[[kk]] = cbind(beta.Bp[[kk]], plot.Bp[[kk]]$fit)
      }
      beta.Bp[[1]][,i] <- beta.Bp[[1]][,i] + fit.Bp$coefficients[1]
    }
  }
  
  # To get confidence bands of beta(s)
  beta.band.lower <- matrix(unlist(lapply(1:(n.cov+1), function(x){
    apply(beta.Bp[[x]], 1, function(row)  mean(row)-qnorm(0.975)*sd(row) ) })),
    ncol=(n.cov+1), byrow=FALSE)
  beta.band.upper <- matrix(unlist(lapply(1:(n.cov+1), function(x){
    apply(beta.Bp[[x]], 1, function(row)  mean(row)+qnorm(0.975)*sd(row) ) })), 
    ncol=(n.cov+1), byrow=FALSE)
  
  return(list(Y.mean.init = Y.mean.init,
              beta.init = beta.init,
              beta.Bp = beta.Bp,
              beta.band.lower = beta.band.lower,
              beta.band.upper = beta.band.upper))
}  

```

**2. Generate a sample dataset (100 subjects, visit times follow Unif[3,6]), and evaluate the function `fgee`**

**2.1 Generating functon**
```{r message=FALSE, echo=FALSE}
library(MASS)
GenerateData <- function(Nsubj=100, numFunctPoints = 101, min_visit=8, max_visit=12,
                         numLongiPoints = 41, sigma_sq = 1.5, 
                         sigma_z11 = 3, sigma_z12 = 1.5, 
                         sigma_z21 = 2, sigma_z22 = 1,
                         corstr = c("unspecified", "exchangeable", "independent")){
  # Arguments:
  # Nsubj -- number of subjects, default to 100
  # numFunctPoints - number of points at which functions are observed
  # min_visit = 8 #(min # visits is 8) - minimum number of visits for each subject
  # max_visit = 12 #(max # visits is 12) - maximum number of visits for each subject
  # numLongiPoints -- number of points to evaluate inner eigenfunctions (for visits) on 
  # inner (visits) eigenfunction scores
  # sigma_sq -- white noise variance defaults to 1.5 for SNR = 5 (see Ana-Maria paper)
  # sigma_z11 <- 3
  # sigma_z12 <- 1.5
  # sigma_z21 <- 2
  # sigma_z22 <- 1
  ############################################################
  psi = NULL 
  xi = NULL
  zeta = NULL
  sigma = NULL
  # time points at which functional responses are collected
  s <- seq(0, 1, length = numFunctPoints)
  
  ########################################
  # Select time points for visits j
  ########################################
  # vector of visit argvalues T of length numLongiPoints
  T <- seq(0, 1, len = numLongiPoints) 
    
  # select number of visits per subject from uniform distribution
  runifdisc <- function(n, min=0, max=1) {sample(min:max, n, replace=TRUE)}
  m_i <- runifdisc(n=Nsubj, min = min_visit, max = max_visit)
  
  # vector of subject visits
  subjID <- rep(1:Nsubj, m_i)
  n <- length(subjID)
  
  # select for each subject i from all possible argvalues T, subject visits of length m_i
  Tij <- lapply(m_i, function(x){sort(sample(T, size = x, replace = FALSE))})
  # keep indicators for the visit number selected
  visitID <- lapply(Tij, function(x) which(T %in% x))
  # convert into a vector
  Tij <- unlist(Tij)
  visitID <- unlist(visitID)
  # create column id names 
  times <- paste("t_", 1:length(s), sep = "")
  # create row id names
  visits <- paste("S_", subjID, "v_", visitID , sep="")
  
  ########################################
  # Define k=2 outer basis functions 
  ########################################
  b_per <- 2
  phi_1 = function(s) {rep(1, length(s))}
  phi_2 = function(s, b_per=2) {sqrt(2) * sin (b_per*pi*s)}
  # phi values
  phi <- list()
  phi$phi_1 <- phi_1(s)
  phi$phi_2 <- phi_2(s)
  ########################################
  # Define covariates
  ########################################
  Cov1.pred <- rnorm(Nsubj)
  Cov1 <- rep(Cov1.pred, m_i)
  a <- 1
  pho <- 0.7
  ar.sim <- unlist(lapply(m_i,function(b){arima.sim(model=list(ar=pho), n=b)}))
  Cov2 <- a*Tij + ar.sim
  Cov <- cbind(Cov1,Cov2)
  rownames(Cov) <- visits
  colnames(Cov) <- c("X1", "X2")
  
  ########################################
  # Define mean response functions
  ########################################
  beta0 <- sqrt(2)*cos(3*pi*s) + 1
  beta1 <- 2 + cos(2*pi*s)
  beta2 <- 2 + sin(pi*s)
  
  ############################################################
  # Define mean function at each time (s) and visit (T) point 
  #############################################################
  mean <- Cov%*%t(cbind(beta1,beta2)) + matrix(rep(beta0,n), nr=n, byrow = TRUE) 
  rownames(mean) <- visits
  colnames(mean) <- times
  
  if(corstr == "unspecified"){
    ########################################################
    # Define time varying components
    # xi_ik(T) = zeta_ik1 psi_k1(T) + zeta_ik2 psi_k2(T)
    ########################################################
  
    #define psi_k1 and psi_k2
    psi_11 <- function(T) {sqrt(2) * cos (2*pi*T)}
    psi_12 <- function(T) {sqrt(2) * sin (2*pi*T)}
    psi_21 <- function(T) {sqrt(2) * cos (4*pi*T)}
    psi_22 <- function(T) {sqrt(2) * sin (4*pi*T)}
  
    # calculate eigenfunctions values at each point
    psi <- list()
    psi$psi_11 <- psi_11(T)
    psi$psi_12 <- psi_12(T) 
    psi$psi_21 <- psi_21(T)
    psi$psi_22 <- psi_22(T) 
  
    # define zeta_k1 and zeta_k2
    zeta_11 <- rnorm(n = Nsubj, mean = 0, sd = sqrt(sigma_z11-1))
    zeta_12 <- rnorm(n = Nsubj, mean = 0, sd = sqrt(sigma_z12))
    zeta_21 <- rnorm(n = Nsubj, mean = 0, sd = sqrt(sigma_z21-0.5))
    zeta_22 <- rnorm(n = Nsubj, mean = 0, sd = sqrt(sigma_z22))
    # zeta values that will be used for evaluation, inner eigenfunctions scores
    zeta <- list()
    zeta$zeta_11 <- zeta_11
    zeta$zeta_12 <- zeta_12
    zeta$zeta_21 <- zeta_21
    zeta$zeta_22 <- zeta_22
    
    # create xi's
    xi_1 <- rep(zeta_11, m_i)*psi$psi_11[visitID] + rep(zeta_12,m_i)*psi$psi_12[visitID]
    names(xi_1) <- visits
    xi_2 <- rep(zeta_21, m_i)*psi$psi_21[visitID] + rep(zeta_22,m_i)*psi$psi_22[visitID]
    names(xi_2) <- visits
    # xi values that will be used for evaluation
    xi <-list()
    xi$xi_1 <- xi_1
    xi$xi_2 <- xi_2

    ########################################
    # define X_i(s, T_ij)
    # X_i(s, T_ij) = xi_1*phi_1 + xi_2*phi_2
    ########################################
    X <- xi_1%*%matrix(phi_1(s), nrow=1) + xi_2%*%matrix(phi_2(s), nrow=1)
    rownames(X) <- visits
    colnames(X) <- times
    
    ########################################
    # Generate random error terms
    # there are (i=length(s))*(j=sum(m_i)) = #time points * #visits for all subjects
    ########################################
    # noise/signal = 1:5
    inner.noise_1 <- rnorm(n = n, mean = 0, sd = sqrt(1))
    inner.noise_2 <- rnorm(n = n, mean = 0, sd = sqrt(0.5))
    epsilon.inner <- (inner.noise_1)%*%matrix(phi_1(s), nrow=1) 
    + (inner.noise_2)%*%matrix(phi_2(s), nrow=1)
    rownames(epsilon.inner) <- visits
    colnames(epsilon.inner) <- times
    
    # outer noise
    epsilon <- matrix(rnorm(n*numFunctPoints, mean = 0, sd = sqrt(sigma_sq)), 
                      nrow = n, ncol = numFunctPoints)
    # assign row and column names to error terms matrix epsilon_ij
    rownames(epsilon) <- visits
    colnames(epsilon) <- times
    
    ########################################
    # get data Y_ij(s) = mu(s,T_ij) + X_i(s, T_ij) + epsilon.inner_ij(s) + epsilon_ij(s)
    ########################################
    Y = mean + X + epsilon.inner + epsilon 
    Y.star = mean + X 
    }#end if corstr == unspecified
  
  else if (corstr == "exchangeable"){
    # k=1
    # subject specific random effects
    xi_i1_coef <- rnorm(n = Nsubj, mean = 0, sd = sqrt(sigma_z11))
    names(xi_i1_coef) <- paste("S_", 1:Nsubj, sep="")
    xi_i1 <- rep(xi_i1_coef, m_i)
    names(xi_i1) <- visits
    # subject-visit specific effects
    xi_ij1 <- rnorm(sum(m_i), mean =0, sd = sqrt(sigma_z12))
    names(xi_ij1) <- visits
    # k=2
    # define subject-visit specific effects
    xi_i2_coef <- rnorm(n = Nsubj, mean = 0, sd = sqrt(sigma_z21))
    names(xi_i2_coef) <- paste("S_", 1:Nsubj, sep="")
    xi_i2 <- rep(xi_i2_coef, m_i)
    names(xi_i2) <- visits
    # subject-visit specific effects
    xi_ij2 <- rnorm(sum(m_i), mean =0, sd = sqrt(sigma_z22))  
    names(xi_ij2) <- visits
    
    # xi values that will be used for evaluation
    # subject scores
    xi <-list()
    xi$xi_i1 <- xi_i1_coef
    xi$xi_i2 <- xi_i2_coef
    # subject-visit specific
    xi$xi_ij1 <- xi_ij1
    xi$xi_ij2 <- xi_ij2
    
    # define X_i(s, T_ij)
    # subject specific random process U_i
    U_i = t(matrix(phi_1(s))%*%xi_i1) + t(matrix(phi_2(s))%*%xi_i2)
    rownames(U_i) <- visits
    colnames(U_i) <- times
    
    # subject-visit specific random process V_ij
    V_ij <-  t(matrix(phi_1(s))%*%xi_ij1) + t(matrix(phi_2(s))%*%xi_ij2)
    rownames(V_ij) <- visits
    colnames(V_ij) <- times
    # response X = U_i + V_ij 
    X = U_i + V_ij 
    ########################################
    # Generate random error terms
    # there are (i=length(s))*(j=sum(m_i)) = #time points * #visits for all subjects
    ########################################
    epsilon <- matrix(rnorm(n*numFunctPoints, mean = 0, sd = sqrt(sigma_sq)), 
                      nrow = n, ncol = numFunctPoints)
    # assign row and column names to error terms matrix epsilon_ij
    rownames(epsilon) <- visits
    colnames(epsilon) <- times
    
    ########################################
    # combine to get data Y_ij(s) = mu(s,T_ij) + X_i(s, T_ij) + epsilon_ij(s)
    ########################################
    Y = mean + X + epsilon #response function used for evaluation (matrix form)
    Y.star = mean + X #used for accuracy evaluation
    }#end if corstr == exchangeable
  
  else if (corstr == "independent"){
    # k=1
    # subject-visit specific effects
    xi_ij1 <- rnorm(sum(m_i), mean =0, sd = sqrt(sigma_z11+sigma_z12))
    names(xi_ij1) <- visits
    # k=2
    # subject-visit specific effects
    xi_ij2 <- rnorm(sum(m_i), mean =0, sd = sqrt(sigma_z21+sigma_z22))  
    names(xi_ij2) <- visits
    
    # xi values that will be used for evaluation
    # subject-visit specific scores
    xi <-list()
    xi$xi_ij1 <- xi_ij1
    xi$xi_ij2 <- xi_ij2
    
    # define X_i(s, T_ij)
    # subject-visit specific random process V_ij
    V_ij <-  t(matrix(phi_1(s))%*%xi_ij1) + t(matrix(phi_2(s))%*%xi_ij2)
    rownames(V_ij) <- visits
    colnames(V_ij) <- times
    # response X = V_ij 
    X = V_ij 
    ########################################
    # Generate random error terms
    # there are (i=length(s))*(j=sum(m_i)) = #time points * #visits for all subjects
    ########################################
    epsilon <- matrix(rnorm(n*numFunctPoints, mean = 0, sd = sqrt(sigma_sq)), 
                      nrow = n, ncol = numFunctPoints)
    # assign row and column names to error terms matrix epsilon_ij
    rownames(epsilon) <- visits
    colnames(epsilon) <- times
    
    ########################################
    # combine to get data Y_ij(s) = mu(s,T_ij) + X_i(s, T_ij) + epsilon_ij(s)
    ########################################
    Y = mean + X + epsilon #response function used for evaluation (matrix form)
    Y.star = mean + X #used for accuracy evaluation
    }#end if corstr == independent
  
  return(list(data=list(subjID=subjID, Tij=Tij, visitID=visitID, funcArg=s, Y=Y, 
          Cov=Cov), X=X, Y.star=Y.star, mean=mean, beta=cbind(beta0,beta1,beta2), 
          phi=phi, xi=xi, psi=psi, zeta=zeta))
  
}#end of function GenerateData
```

**2.2 Generate data with unspecified covariance structure and estimate**

The mean function $\mu_{ij}(s) = \sqrt{2}\cos(3\pi s) + 1 + x_{1ij} (2+\cos(2\pi s)) + x_{2ij} (2+\sin(\pi s))$. We estimate the mean function by five models. 1. The naive estimation by `pffr` function without considering any covariance structure. 2. The bootstrap method to get correct confidence bands for naive estimation (as menthioned before, since this part took a long time, we commented it). 3. The fgee estimation with independent covariance. 4. The fgee estimation with exchangeable covariance. 5. The fgee estimation with unspecified covariance. 

```{r message=FALSE}
library(ggplot2)
library(refund)
library(face)
library(fields)
library(mgcv)
library(gridExtra)

# generate dataset with unspecified covariance
set.seed(2021)
data <- GenerateData(Nsubj=100, numFunctPoints=101, min_visit=3, max_visit=6,
                     numLongiPoints=41, sigma_sq=1.5, sigma_z11=3, sigma_z12=1.5, 
                     sigma_z21=2, sigma_z22=1, corstr = "unspecified")

# bootstrape to get correct confidence bands for naive estimation
# bp.estim <- fgee_initBp(formula = Y ~ X1 + X2, 
#                               Y=data$data$Y, Cov=data$data$Cov,
#                               s=data$data$funcArg, subjID=data$data$subjID,
#                               Tij=data$data$Tij, n.Bp=300)

# estimate mean functions with independent covariance
iid.estim <- fgee(formula = Y ~ X1 + X2, Y=data$data$Y, Cov=data$data$Cov,
              s=data$data$funcArg, subjID=data$data$subjID, 
              Tij=data$data$Tij, numLongiPoints=41,
              control=list(FPCA1.pve=0.95, FPCA1.knots=20),
              corstr = "independent")

# estimate mean functions with exchangeable covariance
exch.estim <- fgee(formula = Y ~ X1 + X2, Y=data$data$Y, Cov=data$data$Cov,
              s=data$data$funcArg, subjID=data$data$subjID, 
              Tij=data$data$Tij, numLongiPoints=41,
              control=list(FPCA1.pve=0.95, FPCA1.knots=20),
              corstr = "exchangeable")

# estimate mean functions with unspecified covariance
unsp.estim <- fgee(formula = Y ~ X1 + X2, Y=data$data$Y, Cov=data$data$Cov,
              s=data$data$funcArg, subjID=data$data$subjID, 
              Tij=data$data$Tij, numLongiPoints=41,
              control=list(FPCA1.pve=0.95, FPCA2.pve=0.95, FPCA1.knots=20, FPCA2.knots=15),
              corstr = "unspecified")

```

**3. Visualize results**

**3.1 Visualize estimated eigenfunctions vs. true eigenfunctions **
```{r fig.width=8, fig.height=3}
### FPCA ###
flip <-  function(fn_hat, fn){
  len = length(fn)
  dif1 <- sum((fn - fn_hat)^2)/len #if signs are the same
  dif2 <- sum((fn + fn_hat)^2)/len #if signs are opposite
  Ind <- which(c(dif1,dif2) == min(dif1, dif2))
  if(Ind==1){
    return(1)
  }else{
    return(-1)
    }
}

# true eigen-functions
efun.true <- data$phi 
sign1 <- flip(unsp.estim$phi[,1], efun.true$phi_1)
sign2 <- flip(unsp.estim$phi[,2], efun.true$phi_2)
efun <- cbind(sign1*unsp.estim$phi[,1], sign2*unsp.estim$phi[,2])
 
phi1 <- data.frame(estimated=efun[,1], true=efun.true$phi_1, s=seq(0,1,length=101))
phi2 <- data.frame(estimated=efun[,2], true=efun.true$phi_2, s=seq(0,1,length=101))

g1 = ggplot() + 
  geom_line(data=phi1, aes(x=s, y=estimated, linetype="estimated")) +
  geom_line(data=phi1, aes(x=s, y=true, linetype="true")) +
  labs(title = expression(paste("True vs. estimated ", phi[1](s))), x="s", y="") +
  scale_linetype_manual(values=c('estimated'='solid','true'='dashed')) +
  ylim(0,1.5)+theme(legend.position=c(0.17,0.33),legend.title=element_blank())

g2 = ggplot() + 
  geom_line(data=phi2, aes(x=s, y=estimated, linetype="estimated")) +
  geom_line(data=phi2, aes(x=s, y=true, linetype="true")) +
  labs(title = expression(paste("True vs. estimated ", phi[2](s))), x="s", y="") +
  scale_linetype_manual(values=c('estimated'='solid','true'='dashed')) +
  ylim(-1.6,1.6)+theme(legend.position=c(0.17,0.33),legend.title=element_blank())
figure <- grid.arrange(g1, g2, ncol=2)
```

**3.2 Visualize estimated $\beta$ functions given by `fgee` with unspecified covariance and given by `pffr` function **
```{r fig.width=8, fig.height=3}
# estimated beta by fgee with unspecified covariance ###
beta.unsp <- unsp.estim$beta
beta.unsp.se <- unsp.estim$beta.se

lower <- beta.unsp - qnorm(0.975)*beta.unsp.se 
upper <- beta.unsp + qnorm(0.975)*beta.unsp.se 
s <- seq(0, 1, length = 101)
unsp_beta <- data.frame(beta0=beta.unsp[,1], beta0.true=sqrt(2)*cos(3*pi*s)+1, 
                        beta0_l=lower[,1], beta0_u=upper[,1],
                        beta1=beta.unsp[,2], beta1.true=2 + cos(2*pi*s),
                        beta1_l=lower[,2], beta1_u=upper[,2],
                        beta2=beta.unsp[,3], beta2.true=2 + sin(pi*s), 
                        beta2_l=lower[,3], beta2_u=upper[,3], 
                        s=seq(0, 1, length=101))

p1 <- ggplot(unsp_beta, aes(x=s, y=beta0)) +
  geom_smooth(aes(ymin=beta0_l, ymax=beta0_u), alpha=0.4, stat="identity") +
  geom_line(aes(x=s, y=beta0.true)) +
  xlab("s") + ylab(expression(beta[0](s))) 
p2 <-  ggplot(unsp_beta, aes(x = s, y = beta1)) +
  geom_smooth(aes(ymin=beta1_l, ymax=beta1_u), alpha=0.4, stat="identity") +
  geom_line(aes(x=s, y=beta1.true)) +
  xlab("s") + ylab(expression(beta[1](s)))
p3 <- ggplot(unsp_beta, aes(x=s, y=beta2)) +
  geom_smooth(aes(ymin=beta2_l, ymax=beta2_u), alpha=0.4, stat="identity") +
  geom_line(aes(x=s, y=beta2.true)) +
  xlab("s") + ylab(expression(beta[2](s))) 

figure <- grid.arrange(p1, p2, p3, ncol=3, 
          top="Estimated coefficient functions by fgee with unspecified covariance",
  bottom ="The blue line is the estimated one and the black line is the true one")

# estimated beta by naive pffr function 
beta.naive <- unsp.estim$beta.init
beta.naive.se <- unsp.estim$beta.init.se

lower <- beta.naive - qnorm(0.975)*beta.naive.se 
upper <- beta.naive + qnorm(0.975)*beta.naive.se 
naive_beta <- data.frame(beta0=beta.naive[,1], beta0.true=sqrt(2)*cos(3*pi*s)+1, 
                         beta0_l=lower[,1], beta0_u=upper[,1],
                       beta1=beta.naive[,2], beta1.true=2 + cos(2*pi*s),
                       beta1_l=lower[,2], beta1_u=upper[,2],
                       beta2=beta.naive[,3], beta2.true=2 + sin(pi*s),
                       beta2_l=lower[,3], beta2_u=upper[,3], 
                       s=seq(0, 1, length=101))

p1 <- ggplot(naive_beta, aes(x=s, y=beta0)) +
  geom_smooth(aes(ymin=beta0_l, ymax=beta0_u), alpha=0.4, stat="identity") +
  geom_line(aes(x=s, y=beta0.true)) +
  xlab("s") + ylab(expression(beta[0](s))) 
p2 <-  ggplot(naive_beta, aes(x = s, y = beta1)) +
  geom_smooth(aes(ymin=beta1_l, ymax=beta1_u), alpha=0.4, stat="identity") +
  geom_line(aes(x=s, y=beta1.true)) +
  xlab("s") + ylab(expression(beta[1](s)))
p3 <- ggplot(naive_beta, aes(x=s, y=beta2)) +
  geom_smooth(aes(ymin=beta2_l, ymax=beta2_u), alpha=0.4, stat="identity") +
  geom_line(aes(x=s, y=beta2.true)) +
  xlab("s") + ylab(expression(beta[2](s))) 
figure <- grid.arrange(p1, p2, p3, ncol=3, 
                    top="Estimated coefficient functions by naive pffr function",
bottom ="The blue line is the estimated one and the black line is the true one")

# estimated beta by bootstrap to get better confidence bands ###
# beta.Bp <- bp.estim$beta.init
# lower <- bp.estim$beta.band.lower
# upper <- bp.estim$beta.band.upper
# Bp_beta = data.frame(beta0=beta.Bp[,1], beta0.true=sqrt(2)*cos(3*pi*s)+1,
#                      beta0_l=lower[,1], beta0_u=upper[,1],
#                      beta1=beta.Bp[,2], beta1.true=2 + cos(2*pi*s),
#                      beta1_l=lower[,2], beta1_u=upper[,2],
#                      beta2=beta.Bp[,3], beta2.true=2 + sin(pi*s),
#                      beta2_l=lower[,3], beta2_u=upper[,3],
#                      s=seq(0, 1, length=101))
# p1 <- ggplot(Bp_beta, aes(x = s, y = beta0)) +
#   geom_smooth(aes(ymin=beta0_l, ymax=beta0_u), alpha=0.4, stat="identity") +
#   geom_line(aes(x=s, y=beta0.true)) +
#   xlab("s") + ylab(expression(beta[0](s)))
# p2 <-  ggplot(Bp_beta, aes(x = s, y = beta1)) +
#   geom_smooth(aes(ymin=beta1_l, ymax=beta1_u), alpha=0.4, stat="identity") +
#   geom_line(aes(x=s, y=beta1.true)) +
#   xlab("s") + ylab(expression(beta[1](s)))
# p3 <-  ggplot(Bp_beta, aes(x = s, y = beta2)) +
#   geom_smooth(aes(ymin=beta2_l, ymax=beta2_u), alpha=0.4, stat="identity") +
#   geom_line(aes(x=s, y=beta2.true)) +
#   xlab("s") + ylab(expression(beta[2](s)))
# figure <- grid.arrange(p1, p2, p3, ncol=3,
#                        top="Estimated coefficient functions by bootstrap",
#  bottom ="The blue line is the estimated one and the black line is the true one")
```

**3.3 Calculate $\sqrt{\text{MISE}}$, IAW and IAC for each method**
```{r}
# function to estimate sqrt(MISE) of each beta
beta_MISE <- function(beta.hat, beta.true, numFunctPoints){
    beta0 <- sum((beta.hat[,1]-beta.true[,1])^2)/numFunctPoints
    beta1 <- sum((beta.hat[,2]-beta.true[,2])^2)/numFunctPoints
    beta2 <- sum((beta.hat[,3]-beta.true[,3])^2)/numFunctPoints
    return(c(sqrt(beta0), sqrt(beta1), sqrt(beta2)))
}

# function to estimate IAW and IAC of each beta
eval.beta.CI <- function(beta.hat, beta.se, beta.true, numFunctPoints){
  # fixed effects functions  beta(s)
  beta0 <- beta.true[,1]
  beta1 <- beta.true[,2]
  beta2 <- beta.true[,3]
  
  # IAW of 95% confidence interval 
  IAW <- c(sum(2*qnorm(0.975)*beta.se[,1]),sum(2*qnorm(0.975)*beta.se[,2]),
                  sum(2*qnorm(0.975)*beta.se[,3]))/numFunctPoints
  
  # beta0(s)
  lower <- beta.hat[,1] - qnorm(0.975)*beta.se[,1]
  upper <- beta.hat[,1] + qnorm(0.975)*beta.se[,1]
  # count number of points 
  k1 <- 0 
  for(i in 1:numFunctPoints){
    if(beta0[i]>=lower[i] & beta0[i]<=upper[i]) 
      k1 <- k1 + 1
  }
  IAC.beta0 <- k1/numFunctPoints
  # beta1(s)
  lower <- beta.hat[,2] - qnorm(0.975)*beta.se[,2]
  upper <- beta.hat[,2] + qnorm(0.975)*beta.se[,2]
  # count number of points 
  k2 <- 0 
  for(i in 1:numFunctPoints){
    if(beta1[i]>=lower[i] & beta1[i]<=upper[i]) 
      k2 <- k2 + 1
  }
  IAC.beta1 <- k2/numFunctPoints
  # beta2(s)
  lower <- beta.hat[,3] - qnorm(0.975)*beta.se[,3]
  upper <- beta.hat[,3] + qnorm(0.975)*beta.se[,3]
  # count number of points 
  k3 <- 0 
  for(i in 1:numFunctPoints){
    if(beta2[i]>=lower[i] & beta2[i]<=upper[i]) 
      k3 <- k3 + 1
  }
  IAC.beta2 <- k3/numFunctPoints
  
  IAC <- c(IAC.beta0, IAC.beta1, IAC.beta2)
  
  return(list(IAW=IAW, IAC=IAC))
}

# function to estimate IAW and IAC of bootstrap confiddence bands
eval.betaBp.CI <- function(beta.lower, beta.upper, beta.true, numFunctPoints){
  # fixed effects functions  beta(s)
  beta0 <- beta.true[,1]
  beta1 <- beta.true[,2]
  beta2 <- beta.true[,3]
  
  beta0.band <- cbind(beta.lower[,1], beta.upper[,1])
  beta1.band <- cbind(beta.lower[,2], beta.upper[,2])
  beta2.band <- cbind(beta.lower[,3], beta.upper[,3])
  
  # IAW of 95% confidence interval 
  IAW <- c(sum(beta0.band[,2]-beta0.band[,1]),sum(beta1.band[,2]-beta1.band[,1]),
           sum(beta2.band[,2]-beta2.band[,1]))/numFunctPoints
  
  # beta0(s)
  k1 <- 0 
  for(i in 1:numFunctPoints){
    if(beta0[i]>=beta0.band[i,1] & beta0[i]<=beta0.band[i,2]) 
      k1 <- k1+1
  }
  IAC.beta0 <- k1/numFunctPoints
  # beta1(s)
  k2 <- 0 
  for(i in 1:numFunctPoints){
    if(beta1[i]>=beta1.band[i,1] & beta1[i]<=beta1.band[i,2]) 
      k2 <- k2+1
  }
  IAC.beta1 <- k2/numFunctPoints
  # beta2(s)
  k3 <- 0 
  for(i in 1:numFunctPoints){
    if(beta2[i]>=beta2.band[i,1] & beta2[i]<=beta2.band[i,2]) 
      k3 <- k3+1
  }
  IAC.beta2 <- k3/numFunctPoints
  
  IAC <- c(IAC.beta0, IAC.beta1, IAC.beta2)
  
  return(list(IAW = IAW, IAC = IAC))
}

# calculate 
numFunctPoints = 101
beta.true <- data$beta
# naive pffr function
naive.MISE <- beta_MISE(beta.hat=unsp.estim$beta.init, beta.true, numFunctPoints)
naive.CI <- eval.beta.CI(beta.hat=unsp.estim$beta.init, beta.se=unsp.estim$beta.init.se,
                            beta.true=beta.true, numFunctPoints)
naive.IAW <- naive.CI$IAW
print("MISE by naive pffr")
naive.MISE
print("IAW by naive pffr")
naive.IAW

# bootstrap
# bp.MISE <- beta_MISE(beta.hat=unsp.estim$beta.init, beta.true, numFunctPoints)
# bp.CI <- eval.betaBp.CI(beta.lower=bp.estim$beta.band.lower, 
#          beta.upper=bp.estim$beta.band.upper, beta.true=beta.true, numFunctPoints)
# bp.IAW <- bp.CI$IAW
# print("MISE by naive pffr")
# bp.MISE
# print("IAW by bootstrap")
# bp.IAW

# fgee with independent covariance
iid.MISE <- beta_MISE(beta.hat=iid.estim$beta, beta.true, numFunctPoints)
iid.CI <- eval.beta.CI(beta.hat=iid.estim$beta, beta.se=iid.estim$beta.se,
                            beta.true=beta.true, numFunctPoints) 
iid.IAW <- iid.CI$IAW
print("MISE by fgee with independent covariance")
iid.MISE
print("IAW by fgee with independent covariance")
iid.IAW

# fgee with exchangeable covariance
exch.MISE <- beta_MISE(beta.hat=exch.estim$beta, beta.true, numFunctPoints)
exch.CI <- eval.beta.CI(beta.hat=exch.estim$beta, beta.se=exch.estim$beta.se,
                            beta.true=beta.true, numFunctPoints) 
exch.IAW <- exch.CI$IAW
print("MISE by fgee with exchangeable covariance")
exch.MISE
print("IAW by fgee with exchangeable covariance")
exch.IAW

# fgee with unspecified covariance
unsp.MISE <- beta_MISE(beta.hat=unsp.estim$beta, beta.true, numFunctPoints)
unsp.CI <- eval.beta.CI(beta.hat=unsp.estim$beta, beta.se=unsp.estim$beta.se,
                            beta.true=beta.true, numFunctPoints) 
unsp.IAW <- unsp.CI$IAW
print("MISE by fgee with unspecified covariance")
unsp.MISE
print("IAW by fgee with unspecified covariance")
unsp.IAW
```

**4. Test covariance structure**

**4.1 Main functions applied in the hypothesis test**
```{r message=FALSE,echo=FALSE}
# Purpose: Calculates smooth mean using 10 thin plate regression splines
calc.mean<-function(data){ 
  # smooth mean
  gam0<-gam(as.vector(data$.value)~s(data$.index,k=10))
  return(gam0$fitted.values)
}

# Purpose: Calculates the Kronecker product of Y_i x Y_i for estimating alternative cov
calc.RA <- function(data){
  y <- data$.value
  t <- data$.index
  subj <- data$.id
  usubj <- unique(subj)
  n <- length(usubj)
  R <- c()
  for(i in 1:n){
    index <- which(subj==usubj[i])
    mi <- length(index)
    ti <- t[index]
    yi <- y[index]
    Ji <- matrix(1,mi,mi)
    diag(Ji) <- 0
    di <- c(Ji)
    Ri <- (yi%x%yi)[which(di==1)]
    R <- c(R,Ri)
  }
  return(c(R))
}

# Purpose: Calculates the error variance based on a covariance estimate (input: C)
calc.sigsq <- function(data,C,times){
  ymat <- irreg2mat.mod(data,times) # dense mat
  nsubj <- nrow(ymat)
  
  Rii <- t(sapply(1:nsubj,function(x) ymat[x,]^2)) # Yij * Yij
  diag.cov <- colMeans(Rii, na.rm=TRUE) # diag of sample cov
  diag.cov[is.nan(diag.cov)]<-0
  ind.low<-which(abs(times-quantile(times,0.25))==min(abs(times-quantile(times,0.25))))
  ind.high<-which(abs(times-quantile(times,0.75))==min(abs(times-quantile(times,0.75))))
  return(2*max(0,sintegral(times[ind.low:ind.high],
                           (diag.cov-diag(C))[ind.low:ind.high])$value))
}

# Purpose: Transform functional data in "long" format to "wide" grid, with NA for missing obs
irreg2mat.mod<-function(data,times){
  grid<-matrix(NA,nrow=length(unique(data$.id)),ncol=length(times))
  inds<-cbind(data$.id,match(data$.index,times))
  grid[inds]<-data$.value
  return(grid)
}

# Purpose: Calculate p-value for the observed Tn from the null approximation
p.bs<-function(stat,bs.stat){
  p<-mean(stat<=bs.stat)
  list(p=p,mean=mean(bs.stat),var=var(bs.stat))
}

# Purpose: Truncates small and negatives eigenvalues to make estimated covariance matrix
# positive-semi definite
trunc.mat<-function(b.fit,R,times){
  Gmat<- matrix(b.fit$Bstar.tensor%*%(b.fit$BtB.inv %*%crossprod(b.fit$B,R)),nrow=length(times))
  Gmat2<- 0.5*(Gmat+t(Gmat))
  eigen.fit<-eigen(Gmat2)
  efuncs<-eigen.fit$vectors
  evals<-as.numeric(eigen.fit$values)
  evals[evals<1e-5]<-0
  return(efuncs %*% tcrossprod(diag(evals),efuncs))
}

# Purpose: Tensor-spline fit data for smooth null and alternative covariance
ts.fit <- function(data,times, H=10){
  p <- 3 #cubic splines: degrees
  knots <- select.knots(seq(0,1,by=0.01), H-p)
  y <- data$.value
  t <- data$.index
  subj <- data$.id
  usubj <- unique(subj)
  n <- length(usubj)
  
  B <- matrix( , nrow = 0,ncol = H^2)
  Time <- matrix( , nrow = 0, ncol = 2)
  Y <- c()
  R <- c()
  
  for(i in 1:n){
    index <- which(subj == usubj[i])
    mi <- length(index)
    ti <- t[index]
    yi <- y[index]
    
    Bi <- spline.des(knots = knots, x= ti, ord = p+1,outer.ok =TRUE)$design
    Btildei <- Bi%x%Bi
    Ji <- matrix(1,mi,mi)
    diag(Ji) <- 0
    di <- c(Ji)
    Bbari <- Btildei[which(di==1),]
    T1i <- (ti%x%rep(1,mi))[which(di==1)]
    T2i <- (rep(1,mi)%x%ti)[which(di==1)]
    Ri <- (yi%x%yi)[which(di==1)]
    
    B <- rbind(B, Bbari)
    Time <- rbind(Time, cbind(T1i, T2i))
    R <- c(R,Ri)
  }
  
  t0 <- times 
  Bstar <- spline.des(knots=knots, x= t0, ord = 4,outer.ok =TRUE)$design
  temp1 <- t(Bstar)%*%Bstar
  Eigen1 <- eigen(temp1)
  A1 <- Eigen1$vectors%*%sqrt(diag(Eigen1$values))%*%t(Eigen1$vectors)
  temp2 <- t(B)%*%B
  Eigen2 <- eigen(temp2)
  BtB.inv <- Eigen2$vectors %*% tcrossprod(diag(1/Eigen2$values),Eigen2$vectors)
  
  return(list(B=B, Bstar=Bstar, Time=Time, R=R, 
              BtB.inv=BtB.inv, Bstar.tensor=Bstar %x% Bstar))
}

# Purpose: Fit null hypothesis covariance matrix coefficience
fitNull.iid<-function(data){
  sigsq0 <- var(data$.value)
  return(sigsq0)
}

# Purpose: Resample function for bootstrap
resample.iid<-function(data,mu,sigsq){
  subj <- data$.id
  usubj <- unique(subj)
  nsubj<-length(unique(data$.id))
  mi <- unlist(lapply(1:nsubj,function(i) length(which(subj==usubj[i]))))
  
  xi_ij <- rnorm(sum(mi), mean=0, sd=sqrt(sigsq))
  
  #mean.null + null.variance
  data.bs<-data.frame(.value=mu+xi_ij, .index=data$.index, .id=data$.id)
  return(data.bs)
}

# Purpose: Fit null hypothesis covariance matrix coefficience
fitNull.exch<-function(data){
  try(lme(.value ~ .id, random = ~ 1|.id, method="ML", data=data))
}

# Purpose: Generate null covariance matrix
calc.R0.exch<-function(fit.null, data){
  subj <- data$.id
  usubj <- unique(subj)
  nsubj <- length(usubj)
  mi <- unlist(lapply(1:nsubj,function(i) length(which(subj==usubj[i]))))
  m <- sum(mi*(mi-1))

  sigsq0 <- as.numeric(VarCorr(fit.null)[1,1])
  Rbar0 <- rep(sigsq0,m)
  return(Rbar0)
}

# Resample function for bootstrap
resample.exch<-function(data, mu, fit.null, sigsq){
  subj <- data$.id
  usubj <- unique(subj)
  nsubj<-length(unique(data$.id))
  mi <- unlist(lapply(1:nsubj,function(i) length(which(subj==usubj[i]))))
  
  sigsq0 <- as.numeric(VarCorr(fit.null)[1,1])
  xi_coef <- rnorm(n = nsubj, mean = 0, sd = sqrt(sigsq0))
  xi_i <- rep(xi_coef, mi)
  xi_ij <- rnorm(sum(mi), mean = 0, sd = sqrt(sigsq))
  
  # mean.null + null.variance
  data.bs<-data.frame(.value=mu+xi_i+xi_ij, .index=data$.index, .id=data$.id)
  return(data.bs)
}

# Purpose: Build function to test independent covariance matrix
test.cov.iid <- function(data, numLongiPoints, nbs=1000, nb=10){
  
  times<-seq(0,1,length.out=numLongiPoints)
  mu<-calc.mean(data)
  
  data.demean <- data.frame(.value=data$.value-mu,.index=data$.index,.id=data$.id)
  b.fit<-ts.fit(data.demean,times=times,H=nb)
  C.alt<-trunc.mat(b.fit,b.fit$R,times) #smooth alt cov
  data.sigsq <- data.frame(y=data$.value-mu,argvals=data$.index,subj=data$.id)
  sigsq<-(face.sparse(data.sigsq))$sigma2
  
  C.null<-matrix(0,nc=numLongiPoints, nr=numLongiPoints) #null cov
  Tn <- norm(C.alt-C.null,type='F')
  
  # bootstrap
  bs.stats<-c()
  bs.success=0
  while(bs.success<nbs){
    this.bs<-resample.iid(data, mu, sigsq)
    mu.bs<-calc.mean(this.bs)
    data.demean.bs <- data.frame(.value=this.bs$.value-mu.bs,
                                 .index=this.bs$.index,.id=this.bs$.id)
    RbarA<-calc.RA(data.demean.bs) #R for alt
    C.alt.bs<-trunc.mat(b.fit,RbarA,times) #slow here
    C.null.bs<-matrix(0,nc=numLongiPoints,nr=numLongiPoints)
    Tn.bs<-norm(C.alt.bs-C.null.bs,type='F')
    bs.stats<-c(bs.stats,Tn.bs) #save bs stats
    bs.success=bs.success+1
  }
  Tn.stats<-p.bs(Tn,unlist(bs.stats))
  
  return(list(C.alt=C.alt, C.null=C.null, Tn=Tn, 
              p=Tn.stats$p, bs.approx=bs.stats, sigsq=sigsq))
}

# Purpose: Build function to test exchangeable covariance matrix
test.cov.exch <- function(data, numLongiPoints, nbs=1000, nb=10){
  
  times<-seq(0,1,length.out=numLongiPoints)
  mu <- calc.mean(data)
  
  data.demean <- data.frame(.value=data$.value-mu, .index=data$.index, .id=data$.id)
  fit.null <- fitNull.exch(data.demean) # null fit
  if('try-error' %in% class(fit.null)){
    # issue with null fit
    next
  }
  
  sigsq0 <- as.numeric(VarCorr(fit.null)[1,1])
  
  b.fit<-ts.fit(data.demean,times=times,H=nb)
  C.alt<-trunc.mat(b.fit,b.fit$R,times) #smooth alt cov
  data.sigsq <- data.frame(y=data$.value-mu, argvals=data$.index, subj=data$.id)
  sigsq<-(face.sparse(data.sigsq))$sigma2
  
  Rbar0.fit<-calc.R0.exch(fit.null,data)
  C.null<-trunc.mat(b.fit,Rbar0.fit,times) #smooth null cov
  Tn <- norm(C.alt-C.null,type='F')
  
  # bootstrap
  bs.stats<-c()
  bs.success=0
  while(bs.success<nbs){
    this.bs<-resample.exch(data, mu, fit.null, sigsq)
    mu.bs <- calc.mean(this.bs)
    data.demean.bs <- data.frame(.value=this.bs$.value-mu.bs,
                                 .index=this.bs$.index, .id=this.bs$.id)
    fit.null.bs<-fitNull.exch(data.demean.bs) # null fit
    if('try-error' %in% class(fit.null)){
      # issue with null fit
      next
    }
    RbarA<-calc.RA(data.demean.bs) #R for alt
    Rbar0.fit.bs<-calc.R0.exch(fit.null.bs,data.demean.bs)
    C.alt.bs<-trunc.mat(b.fit,RbarA,times) #slow here
    C.null.bs<-trunc.mat(b.fit,Rbar0.fit.bs,times) #slow here
    Tn.bs<-norm(C.alt.bs-C.null.bs,type='F')
    bs.stats<-c(bs.stats,Tn.bs) #save bs stats
    bs.success=bs.success+1
  }
  Tn.stats<-p.bs(Tn,unlist(bs.stats))
  
  return(list(C.alt=C.alt, C.null=C.null, Tn=Tn, p=Tn.stats$p, 
              bs.approx=bs.stats, sigsq=sigsq, sigsq0=sigsq0))
}

```

**4.2. Results of hypothesis tests**

Show examples of covariance test. We test two types of null hypothesis. The first is $H_0: G_k(\cdot,\cdot)\quad\text{is independent}$, and the second is $H_0: G_k(\cdot,\cdot)\quad\text{is exchangeable}$. First, we test covariance of data with unspecified covariance structure that is generated in section 2. Obviouly, we would reject the null hypothesis and the p-values would be close to zero. Morevoer, we generate new data with exchangeable covariance (under $H_0: G_k(\cdot,\cdot)\quad\text{is exchangeable}$) and independent covariance ($H_0: G_k(\cdot,\cdot)\quad\text{is independent}$). Then, do hypothesis tests on these data. Due to time limit, we did't run this part. 

```{r message=FALSE}
library(refund)
library(face)
library(fields)
library(mgcv)
library(lme4)
library(MASS)
library(matrixcalc)
library(Matrix)
library(Bolstad)
library(splines)

######################################################################
# Test covariance of data with unspecified structure
######################################################################
dat <- data$data
Y <- dat$Y
Cov <- dat$Cov
numLongiPoints = 41
X1 <- Cov[,1]
X2 <- Cov[,2]
formula <- Y ~ X1 + X2
# initial mean estimates
fit_init <- pffr(formula, yind=dat$funcArg, 
                     bs.yindex = list(bs = "ps", k = 10, m = c(2, 2)))
Y.mean.init <- fitted(fit_init) 
Y.resid <- as.matrix(Y - Y.mean.init)
    
# score
fpca_margin <- fpca.face(Y.resid,center = FALSE, argvals=dat$funcArg, 
                         knots=20, pve=0.95)
score <- fpca_margin$scores/sqrt(length(dat$funcArg))
score1 <- data.frame(.value=score[,1], .index=dat$Tij, .id=dat$subjID)
#score2 <- data.frame(.value=score[,2], .index=dat$Tij, .id=dat$subjID)
    
# test structure of G_k(T,T')
test1 <- test.cov.exch(score1, numLongiPoints=numLongiPoints, nbs=1000, nb=10)
#test2 <- test.cov.exch(score2, numLongiPoints=numLongiPoints, nbs=1000, nb=10)
test3 <- test.cov.iid(score1, numLongiPoints=numLongiPoints, nbs=1000, nb=10)
#test4 <- test.cov.iid(score2, numLongiPoints=numLongiPoints, nbs=1000, nb=10)

test1$p
#test2$p
test3$p
#test4$p  

######################################################################
# Test covariance of data with exchangeable structure
######################################################################

# generate data with exchangeable covariance from function GenerateData
set.seed(2021)
data.exch <- GenerateData(Nsubj=100, numFunctPoints=101, min_visit=3, max_visit=6,
                         numLongiPoints = 41, sigma_sq = 1.5, 
                         sigma_z11=3, sigma_z12=1.5, sigma_z21=2, sigma_z22=1,
                         corstr = "exchangeable")
dat.exch <- data.exch$data
Y <- dat.exch$Y
Cov <- dat.exch$Cov
numLongiPoints = 41
X1 <- Cov[,1]
X2 <- Cov[,2]
formula <- Y ~ X1 + X2
# initial mean estimates
fit_init <- pffr(formula, yind=dat.exch$funcArg, 
                     bs.yindex = list(bs = "ps", k = 10, m = c(2, 2)))
Y.mean.init <- fitted(fit_init) 
Y.resid <- as.matrix(Y - Y.mean.init)
    
# score
fpca_margin <- fpca.face(Y.resid, center = FALSE, argvals=dat.exch$funcArg, 
                         knots=20, pve=0.95)
score <- fpca_margin$scores/sqrt(length(dat.exch$funcArg))
score1 <- data.frame(.value=score[,1], .index=dat.exch$Tij, .id=dat.exch$subjID)
#score2 <- data.frame(.value=score[,2], .index=dat.exch$Tij, .id=dat.exch$subjID)
    
# test structure of G_k(T,T')
#test5 <- test.cov.exch(score1, numLongiPoints=numLongiPoints, nbs=1000, nb=10)
#test6 <- test.cov.exch(score2, numLongiPoints=numLongiPoints, nbs=1000, nb=10)

#test5$p
#test6$p

######################################################################
# Test covariance of data with independent structure
######################################################################

# generate data with independent covariance from function GenerateData
set.seed(2021)
data.iid <- GenerateData(Nsubj=100, numFunctPoints=101, min_visit=3, max_visit=6,
                         numLongiPoints = 41, sigma_sq=1.5, 
                         sigma_z11=3, sigma_z12=1.5, sigma_z21=2, sigma_z22=1,
                         corstr = "independent")
dat.iid <- data.iid$data
Y <- dat.iid$Y
Cov <- dat.iid$Cov
numLongiPoints = 41
X1 <- Cov[,1]
X2 <- Cov[,2]
formula <- Y ~ X1 + X2
# initial mean estimates
fit_init <- pffr(formula, yind=dat.iid$funcArg, 
                     bs.yindex = list(bs = "ps", k = 10, m = c(2, 2)))
Y.mean.init <- fitted(fit_init) 
Y.resid <- as.matrix(Y - Y.mean.init)
    
# score
fpca_margin <- fpca.face(Y.resid,center = FALSE, argvals=dat.iid$funcArg, 
                         knots=20, pve=0.95)
score <- fpca_margin$scores/sqrt(length(dat.iid$funcArg))
score1 <- data.frame(.value=score[,1], .index=dat.iid$Tij, .id=dat.iid$subjID)
#score2 <- data.frame(.value=score[,2], .index=dat.iid$Tij, .id=dat.iid$subjID)
    
# test structure of G_k(T,T')
#test7 <- test.cov.iid(score1, numLongiPoints=numLongiPoints, nbs=1000, nb=10)
#test8 <- test.cov.iid(score2, numLongiPoints=numLongiPoints, nbs=1000, nb=10)

#test7$p
#test8$p
```











